{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test OneLake Query\n",
    "\n",
    "Query data from Fabric OneLake using Python + Azure Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install azure-identity pyarrow pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Configuration\n",
    "WORKSPACE_ID = '9c727ce4-5f7e-4008-b31e-f3e3bd8e0adc'\n",
    "LAKEHOUSE_ID = '06dc42ac-4151-4bb9-94fb-1a03edf49600'\n",
    "\n",
    "# Get Azure credentials\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token('https://storage.azure.com/.default')\n",
    "print('Token acquired!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read parquet from OneLake\n",
    "def read_onelake_parquet(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a parquet file from OneLake and return as DataFrame\"\"\"\n",
    "    base_url = f'https://onelake.dfs.fabric.microsoft.com/{WORKSPACE_ID}/{LAKEHOUSE_ID}'\n",
    "    download_url = f'{base_url}/{file_path}'\n",
    "    headers = {'Authorization': f'Bearer {token.token}'}\n",
    "    \n",
    "    resp = requests.get(download_url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f'Failed to download: {resp.status_code} - {resp.text[:200]}')\n",
    "    \n",
    "    buffer = io.BytesIO(resp.content)\n",
    "    return pq.read_table(buffer).to_pandas()\n",
    "\n",
    "def list_onelake_files(directory: str, recursive: bool = True) -> list:\n",
    "    \"\"\"List files in an OneLake directory\"\"\"\n",
    "    base_url = f'https://onelake.dfs.fabric.microsoft.com/{WORKSPACE_ID}/{LAKEHOUSE_ID}'\n",
    "    url = f'{base_url}?resource=filesystem&recursive={str(recursive).lower()}&directory={directory}'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token.token}',\n",
    "        'x-ms-version': '2021-06-08'\n",
    "    }\n",
    "    \n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f'Failed to list: {resp.status_code}')\n",
    "    \n",
    "    return resp.json().get('paths', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available data files\n",
    "files = list_onelake_files('Files/landing/dealer_scrapes', recursive=True)\n",
    "parquet_files = [f for f in files if f['name'].endswith('.parquet')]\n",
    "print(f'Found {len(parquet_files)} parquet files')\n",
    "\n",
    "# Show unique dealers\n",
    "dealers = set()\n",
    "for f in parquet_files:\n",
    "    parts = f['name'].split('/')\n",
    "    if len(parts) > 4:\n",
    "        dealers.add(parts[4])  # dealer name is 5th part\n",
    "\n",
    "print(f'\\nDealers ({len(dealers)}): {\", \".join(sorted(dealers)[:10])}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample inventory data - first 10 rows from AC Nelsen (2026-01-01)\n",
    "file_path = 'Files/landing/dealer_scrapes/ac_nelsen/2026/01/01/acn_20260101.parquet'\n",
    "df = read_onelake_parquet(file_path)\n",
    "\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'\\nColumns: {list(df.columns)}')\n",
    "print(f'\\n=== First 10 Rows ===')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show key inventory metrics\n",
    "print('Sample Inventory Summary:')\n",
    "print(f\"- Total units: {len(df)}\")\n",
    "print(f\"- Unique makes: {df['make'].nunique()}\")\n",
    "print(f\"- Avg sale price: ${df['sale_price'].dropna().astype(float).mean():,.2f}\")\n",
    "print(f\"- RV Classes: {df['class'].unique().tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
